{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creates doc2vec models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disk Writing Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "doc2vec_directory = \"doc2vec_outputs/\"\n",
    "\n",
    "if not os.path.exists(doc2vec_directory):\n",
    "    os.makedirs(doc2vec_directory)\n",
    "\n",
    "    \n",
    "class JSONStorage:\n",
    "    \"\"\"Dumps items into a json file\"\"\"\n",
    "    def __init__(self, file_name: str):\n",
    "        self.__file = open(file_name, \"a\")\n",
    "\n",
    "    def close(self):\n",
    "        self.__file.close()\n",
    "\n",
    "    def add(self, item: dict):\n",
    "        self.__file.write(json.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus Iterable Class\n",
    "\n",
    "These are classes that allow gensim to stream in the json files containing the ngram corpus of both training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gensim\n",
    "\n",
    "def prepare_ngrams(ngrams_list: list):\n",
    "    for ngram in ngrams_list:\n",
    "        yield \"_\".join(ngram)\n",
    "        \n",
    "        \n",
    "class TestingCorpusIterator:\n",
    "    \"\"\"Treats this corpus as testing data, and returns a dictionary containing two keys: token_list (list of the ngrams) \n",
    "    and label (author id)\"\"\"\n",
    "    def __init__(self, testing_corpus):\n",
    "        self._corpus = testing_corpus\n",
    "        \n",
    "    def __next__(self):\n",
    "        try:\n",
    "            post = json.loads(self._corpus.next())\n",
    "            token_list = list(prepare_ngrams(post[self._corpus.get_ngram_key()]))\n",
    "            return {\"token_list\": token_list, \"label\": post['author_id']}\n",
    "        except EOFError:\n",
    "            # Catch and release to say that we're at the end\n",
    "            self._corpus.reset()\n",
    "            raise StopIteration\n",
    "        \n",
    "        \n",
    "class TrainingCorpusIterator:\n",
    "    \"\"\"Treats this corpus as training data, and returns a tagged document for gensim\"\"\"\n",
    "    def __init__(self, training_corpus):\n",
    "        self._corpus = training_corpus\n",
    "        \n",
    "    def __next__(self):\n",
    "        try:\n",
    "            post = json.loads(self._corpus.next())\n",
    "            token_list = list(prepare_ngrams(post[self._corpus.get_ngram_key()]))\n",
    "            return gensim.models.doc2vec.TaggedDocument(token_list, post['author_id'])\n",
    "        except EOFError:\n",
    "            # Catch and release to say that we're at the end\n",
    "            self._corpus.reset()\n",
    "            raise StopIteration\n",
    "        \n",
    "        \n",
    "class JSONCorpus:\n",
    "    def __init__(self, file_name: str, ngram_key: str, token_only: bool):\n",
    "        self.__file = open(file_name, \"r\")\n",
    "        self.__token_only = token_only\n",
    "        self.__ngram_key = ngram_key\n",
    "        \n",
    "        self.__line_num = 0\n",
    "        \n",
    "    def __iter__(self):\n",
    "        if self.__token_only:\n",
    "            return TestingCorpusIterator(self)\n",
    "        else:\n",
    "            return TrainingCorpusIterator(self)\n",
    "    \n",
    "    def next(self):\n",
    "        print(\"Processing line\", self.__line_num)\n",
    "        self.__line_num += 1\n",
    "        return next(self.__file)\n",
    "    \n",
    "    def get_ngram_key(self):\n",
    "        return self.__ngram_key\n",
    "    \n",
    "    def reset(self):\n",
    "        print(\"Finished processing.\")\n",
    "        self.__line_num = 0\n",
    "        self.__file.seek(0)\n",
    "                              \n",
    "    def close(self):\n",
    "        self.__file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doc2vec Unigram Characters Model\n",
    "\n",
    "Creates and trains the doc2vec model using unigram characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus = JSONCorpus(\"jsons/train_unigram_chars.json\", 'unigram_chars', False)\n",
    "unigram_chars_model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "print(\"Building unigram characters vocabulary...\")\n",
    "unigram_chars_model.build_vocab(training_corpus)\n",
    "print(\"Training unigram characters doc2vec model...\")\n",
    "unigram_chars_model.train(training_corpus, total_examples=unigram_chars_model.corpus_count, epochs=unigram_chars_model.epochs)\n",
    "training_corpus.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer vectors of the unigram characters test corpus using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output = JSONStorage(doc2vec_directory + \"inferred_testing_unigram_chars.json\")\n",
    "for test_post in JSONCorpus(\"jsons/test_unigram_chars.json\", 'unigram_chars', True):\n",
    "    vector = unigram_chars_model.infer_vector(test_post['token_list'])\n",
    "    json_output.add({\"author_id\": test_post[\"label\"], \"output\": pd.Series(vector).to_json(orient='values')})\n",
    "    \n",
    "json_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer vectors of the unigram characters training corpus using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output = JSONStorage(doc2vec_directory + \"inferred_training_unigram_chars.json\")\n",
    "for test_post in JSONCorpus(\"jsons/train_unigram_chars.json\", 'unigram_chars', True):\n",
    "    vector = unigram_chars_model.infer_vector(test_post['token_list'])\n",
    "    json_output.add({\"author_id\": test_post[\"label\"], \"output\": pd.Series(vector).to_json(orient='values')})\n",
    "    \n",
    "json_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doc2vec Bigram Characters Model\n",
    "\n",
    "Creates and trains the doc2vec model using bigram characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus = JSONCorpus(\"jsons/train_bigram_chars.json\", 'bigram_chars', False)\n",
    "bigram_chars_model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "print(\"Building bigram characters vocabulary...\")\n",
    "bigram_chars_model.build_vocab(training_corpus)\n",
    "print(\"Training bigram characters doc2vec model...\")\n",
    "bigram_chars_model.train(training_corpus, total_examples=bigram_chars_model.corpus_count, epochs=bigram_chars_model.epochs)\n",
    "training_corpus.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer vectors of the bigram characters test corpus using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output = JSONStorage(doc2vec_directory + \"inferred_testing_bigram_chars.json\")\n",
    "for test_post in JSONCorpus(\"jsons/test_bigram_chars.json\", 'bigram_chars', True):\n",
    "    vector = bigram_chars_model.infer_vector(test_post['token_list'])\n",
    "    json_output.add({\"author_id\": test_post[\"label\"], \"output\": pd.Series(vector).to_json(orient='values')})\n",
    "    \n",
    "json_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer vectors of the bigram characters training corpus using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output = JSONStorage(doc2vec_directory + \"inferred_training_bigram_chars.json\")\n",
    "for test_post in JSONCorpus(\"jsons/train_bigram_chars.json\", 'bigram_chars', True):\n",
    "    vector = bigram_chars_model.infer_vector(test_post['token_list'])\n",
    "    json_output.add({\"author_id\": test_post[\"label\"], \"output\": pd.Series(vector).to_json(orient='values')})\n",
    "    \n",
    "json_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doc2vec Trigram Characters Model\n",
    "\n",
    "Creates and trains the doc2vec model using trigram characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus = JSONCorpus(\"jsons/train_trigram_chars.json\", 'trigram_chars', False)\n",
    "trigram_chars_model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "print(\"Building trigram characters vocabulary...\")\n",
    "trigram_chars_model.build_vocab(training_corpus)\n",
    "print(\"Training trigram characters doc2vec model...\")\n",
    "trigram_chars_model.train(training_corpus, total_examples=trigram_chars_model.corpus_count, epochs=trigram_chars_model.epochs)\n",
    "training_corpus.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer vectors of the trigram characters test corpus using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output = JSONStorage(doc2vec_directory + \"inferred_testing_trigram_chars.json\")\n",
    "for test_post in JSONCorpus(\"jsons/test_trigram_chars.json\", 'trigram_chars', True):\n",
    "    vector = trigram_chars_model.infer_vector(test_post['token_list'])\n",
    "    json_output.add({\"author_id\": test_post[\"label\"], \"output\": pd.Series(vector).to_json(orient='values')})\n",
    "    \n",
    "json_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer vectors of the trigram characters training corpus using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output = JSONStorage(doc2vec_directory + \"inferred_training_trigram_chars.json\")\n",
    "for test_post in JSONCorpus(\"jsons/train_trigram_chars.json\", 'trigram_chars', True):\n",
    "    vector = trigram_chars_model.infer_vector(test_post['token_list'])\n",
    "    json_output.add({\"author_id\": test_post[\"label\"], \"output\": pd.Series(vector).to_json(orient='values')})\n",
    "    \n",
    "json_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doc2vec Unigram Words Model\n",
    "\n",
    "Creates and trains the doc2vec model using unigram words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus = JSONCorpus(\"jsons/train_unigram_words.json\", 'unigram_words', False)\n",
    "unigram_words_model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "print(\"Building unigram words vocabulary...\")\n",
    "unigram_words_model.build_vocab(training_corpus)\n",
    "print(\"Training unigram words doc2vec model...\")\n",
    "unigram_words_model.train(training_corpus, total_examples=unigram_words_model.corpus_count, epochs=unigram_words_model.epochs)\n",
    "training_corpus.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer vectors of the unigram words test corpus using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output = JSONStorage(doc2vec_directory + \"inferred_testing_unigram_words.json\")\n",
    "for test_post in JSONCorpus(\"jsons/test_unigram_words.json\", 'unigram_words', True):\n",
    "    vector = unigram_words_model.infer_vector(test_post['token_list'])\n",
    "    json_output.add({\"author_id\": test_post[\"label\"], \"output\": pd.Series(vector).to_json(orient='values')})\n",
    "    \n",
    "json_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer vectors of the unigram words training corpus using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output = JSONStorage(doc2vec_directory + \"inferred_training_unigram_words.json\")\n",
    "for test_post in JSONCorpus(\"jsons/train_unigram_words.json\", 'unigram_words', True):\n",
    "    vector = unigram_words_model.infer_vector(test_post['token_list'])\n",
    "    json_output.add({\"author_id\": test_post[\"label\"], \"output\": pd.Series(vector).to_json(orient='values')})\n",
    "    \n",
    "json_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doc2vec Bigram Words Model\n",
    "\n",
    "Creates and trains the doc2vec model using bigram words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus = JSONCorpus(\"jsons/train_bigram_words.json\", 'bigram_words', False)\n",
    "bigram_words_model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "print(\"Building bigram words vocabulary...\")\n",
    "bigram_words_model.build_vocab(training_corpus)\n",
    "print(\"Training bigram words doc2vec model...\")\n",
    "bigram_words_model.train(training_corpus, total_examples=bigram_words_model.corpus_count, epochs=bigram_words_model.epochs)\n",
    "training_corpus.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer vectors of the bigram words test corpus using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output = JSONStorage(doc2vec_directory + \"inferred_testing_bigram_words.json\")\n",
    "for test_post in JSONCorpus(\"jsons/test_bigram_words.json\", 'bigram_words', True):\n",
    "    vector = bigram_words_model.infer_vector(test_post['token_list'])\n",
    "    json_output.add({\"author_id\": test_post[\"label\"], \"output\": pd.Series(vector).to_json(orient='values')})\n",
    "    \n",
    "json_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer vectors of the bigram words training corpus using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output = JSONStorage(doc2vec_directory + \"inferred_training_bigram_words.json\")\n",
    "for test_post in JSONCorpus(\"jsons/train_bigram_words.json\", 'bigram_words', True):\n",
    "    vector = bigram_words_model.infer_vector(test_post['token_list'])\n",
    "    json_output.add({\"author_id\": test_post[\"label\"], \"output\": pd.Series(vector).to_json(orient='values')})\n",
    "    \n",
    "json_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doc2vec Trigram Words Model\n",
    "\n",
    "Creates and trains the doc2vec model using trigram words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus = JSONCorpus(\"jsons/train_trigram_words.json\", 'trigram_words', False)\n",
    "trigram_words_model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "print(\"Building trigram words vocabulary...\")\n",
    "trigram_words_model.build_vocab(training_corpus)\n",
    "print(\"Training trigram words doc2vec model...\")\n",
    "trigram_words_model.train(training_corpus, total_examples=unigram_words_model.corpus_count, epochs=unigram_words_model.epochs)\n",
    "training_corpus.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer vectors of the trigram words test corpus using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output = JSONStorage(doc2vec_directory + \"inferred_testing_trigram_words.json\")\n",
    "for test_post in JSONCorpus(\"jsons/test_trigram_words.json\", 'trigram_words', True):\n",
    "    vector = trigram_words_model.infer_vector(test_post['token_list'])\n",
    "    json_output.add({\"author_id\": test_post[\"label\"], \"output\": pd.Series(vector).to_json(orient='values')})\n",
    "    \n",
    "json_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer vectors of the trigram words training corpus using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output = JSONStorage(doc2vec_directory + \"inferred_training_trigram_words.json\")\n",
    "for test_post in JSONCorpus(\"jsons/train_trigram_words.json\", 'trigram_words', True):\n",
    "    vector = trigram_words_model.infer_vector(test_post['token_list'])\n",
    "    json_output.add({\"author_id\": test_post[\"label\"], \"output\": pd.Series(vector).to_json(orient='values')})\n",
    "    \n",
    "json_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doc2vec Unigram POS Model\n",
    "\n",
    "Creates and trains the doc2vec model using unigram POS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus = JSONCorpus(\"jsons/train_unigram_pos.json\", 'unigram_pos', False)\n",
    "unigram_pos_model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "print(\"Building unigram pos vocabulary...\")\n",
    "unigram_pos_model.build_vocab(training_corpus)\n",
    "print(\"Training unigram pos doc2vec model...\")\n",
    "unigram_pos_model.train(training_corpus, total_examples=unigram_pos_model.corpus_count, epochs=unigram_pos_model.epochs)\n",
    "training_corpus.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer vectors of the unigram POS test corpus using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output = JSONStorage(doc2vec_directory + \"inferred_testing_unigram_pos.json\")\n",
    "for test_post in JSONCorpus(\"jsons/test_unigram_pos.json\", 'unigram_pos', True):\n",
    "    vector = unigram_pos_model.infer_vector(test_post['token_list'])\n",
    "    json_output.add({\"author_id\": test_post[\"label\"], \"output\": pd.Series(vector).to_json(orient='values')})\n",
    "    \n",
    "json_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer vectors of the unigram POS training corpus using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output = JSONStorage(doc2vec_directory + \"inferred_training_unigram_pos.json\")\n",
    "for test_post in JSONCorpus(\"jsons/train_unigram_pos.json\", 'unigram_pos', True):\n",
    "    vector = unigram_pos_model.infer_vector(test_post['token_list'])\n",
    "    json_output.add({\"author_id\": test_post[\"label\"], \"output\": pd.Series(vector).to_json(orient='values')})\n",
    "    \n",
    "json_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doc2vec Bigram POS Model\n",
    "\n",
    "Creates and trains the doc2vec model using bigram POS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus = JSONCorpus(\"jsons/train_bigram_pos.json\", 'bigram_pos', False)\n",
    "bigram_pos_model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "print(\"Building bigram pos vocabulary...\")\n",
    "bigram_pos_model.build_vocab(training_corpus)\n",
    "print(\"Training bigram pos doc2vec model...\")\n",
    "bigram_pos_model.train(training_corpus, total_examples=bigram_pos_model.corpus_count, epochs=bigram_pos_model.epochs)\n",
    "training_corpus.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer vectors of the bigram POS test corpus using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output = JSONStorage(doc2vec_directory + \"inferred_testing_bigram_pos.json\")\n",
    "for test_post in JSONCorpus(\"jsons/test_bigram_pos.json\", 'bigram_pos', True):\n",
    "    vector = bigram_pos_model.infer_vector(test_post['token_list'])\n",
    "    json_output.add({\"author_id\": test_post[\"label\"], \"output\": pd.Series(vector).to_json(orient='values')})\n",
    "    \n",
    "json_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer vectors of the bigram POS training corpus using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output = JSONStorage(doc2vec_directory + \"inferred_training_bigram_pos.json\")\n",
    "for test_post in JSONCorpus(\"jsons/train_bigram_pos.json\", 'bigram_pos', True):\n",
    "    vector = bigram_pos_model.infer_vector(test_post['token_list'])\n",
    "    json_output.add({\"author_id\": test_post[\"label\"], \"output\": pd.Series(vector).to_json(orient='values')})\n",
    "    \n",
    "json_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doc2vec Trigram POS Model\n",
    "\n",
    "Creates and trains the doc2vec model using trigram POS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus = JSONCorpus(\"jsons/train_trigram_pos.json\", 'trigram_pos', False)\n",
    "trigram_pos_model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "print(\"Building trigram pos vocabulary...\")\n",
    "trigram_pos_model.build_vocab(training_corpus)\n",
    "print(\"Training trigram pos doc2vec model...\")\n",
    "trigram_pos_model.train(training_corpus, total_examples=trigram_pos_model.corpus_count, epochs=trigram_pos_model.epochs)\n",
    "training_corpus.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer vectors of the trigram POS test corpus using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output = JSONStorage(doc2vec_directory + \"inferred_testing_trigram_pos.json\")\n",
    "for test_post in JSONCorpus(\"jsons/test_trigram_pos.json\", 'trigram_pos', True):\n",
    "    vector = trigram_pos_model.infer_vector(test_post['token_list'])\n",
    "    json_output.add({\"author_id\": test_post[\"label\"], \"output\": pd.Series(vector).to_json(orient='values')})\n",
    "    \n",
    "json_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer vectors of the trigram POS training corpus using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output = JSONStorage(doc2vec_directory + \"inferred_training_trigram_pos.json\")\n",
    "for test_post in JSONCorpus(\"jsons/train_trigram_pos.json\", 'trigram_pos', True):\n",
    "    vector = trigram_pos_model.infer_vector(test_post['token_list'])\n",
    "    json_output.add({\"author_id\": test_post[\"label\"], \"output\": pd.Series(vector).to_json(orient='values')})\n",
    "    \n",
    "json_output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
